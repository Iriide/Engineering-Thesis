{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7a2da040ba8e290"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('data/filtered_installations.csv')\n",
    "weather_cache = {}\n",
    "\n",
    "# Function to scrape weather data or retrieve it from cache\n",
    "def scrape_weather(url: str):  \n",
    "    # Check if the data for this URL is already in the cache\n",
    "    if url in weather_cache:\n",
    "        print(f\"Using cached data for: {url}\")\n",
    "        return weather_cache[url]\n",
    "\n",
    "    print(f\"Scraping weather data from: {url}\")\n",
    "    # Send a GET request to the webpage\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Lists to store the weather data\n",
    "    times, temperatures, cloudiness_list, humidities, wind_speeds = [], [], [], [], []\n",
    "    \n",
    "    # Extract time and temperature data\n",
    "    for entry in soup.find_all('div', {'class': 'weather-entry'}):\n",
    "        time = entry.find('span', class_='hour').text + \":\" + entry.find('span', class_='minutes').text\n",
    "        temperature = entry.find('span', class_='forecast-temp').text\n",
    "        wind_speed = entry.find('span', class_='speed-value').text + \" \" + entry.find('span', class_='speed-unit').text\n",
    "    \n",
    "        times.append(time)\n",
    "        temperatures.append(temperature[:-2])\n",
    "        wind_speeds.append(wind_speed[:-4])\n",
    "    \n",
    "    # Extract cloudiness data\n",
    "    for cloud_entry in soup.find_all('div', {'class': 'entry-precipitation'}):\n",
    "        cloudiness = cloud_entry.find('span', class_='entry-precipitation-value cloud-cover')\n",
    "        if cloudiness:\n",
    "            cloudiness = int(cloudiness.text[:-1])\n",
    "        else:\n",
    "            cloudiness = 0\n",
    "        cloudiness_list.append(cloudiness)\n",
    "    \n",
    "    # Extract humidity data\n",
    "    for humidity_entry in soup.find_all('div', {'class': 'entry-humidity'}):\n",
    "        humidity = humidity_entry.find('div', class_='entry-humidity-wrap')\n",
    "        if humidity:\n",
    "            humidity = humidity.text.strip()[:-1]\n",
    "        else:\n",
    "            humidity = 0\n",
    "        humidities.append(humidity)\n",
    "    \n",
    "    # Create a DataFrame and store it in the cache\n",
    "    weather_data = {\n",
    "        'Time': times,\n",
    "        'Temperature': temperatures,\n",
    "        'Cloudiness': cloudiness_list,\n",
    "        'Humidity': humidities,\n",
    "        'Wind Speed': wind_speeds\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(weather_data)\n",
    "    \n",
    "    # Save to cache\n",
    "    weather_cache[url] = df\n",
    "    \n",
    "    # Simulate delay between requests\n",
    "    sleep(1)  # To avoid hitting rate limits\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# If dataset does not have those fields, adjust the code accordingly\n",
    "installations_with_weather_df = pd.DataFrame(columns=['id_licznika', 'moc', 'dlugosc', 'szerokosc', 'data', \"dpv\", \"efekt\", 'temperatura', 'zachmurzenie', 'wilgotnosc', 'wiatr'])\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    # Construct the URL for the weather archive page\n",
    "    row['godzina'] = final_df['data']\n",
    "    row['godzina'] = pd.to_datetime(row['godzina'])\n",
    "    date = row['godzina'].strftime('%d-%m-%Y')\n",
    "    hour = row['godzina'].hour\n",
    "    url = f\"https://pogoda.interia.pl/archiwum-pogody-{date},cId,{int(row['index'])}\"\n",
    "    \n",
    "    # Scrape the weather data\n",
    "    weather_df = scrape_weather(url)\n",
    "    print(f\"Weather data for installation {row['id_licznika']} scraped successfully.\")\n",
    "\n",
    "    # Add the 'data' column to the DataFrame where time is the same as hour in final_df\n",
    "    weather_df['Time'] = pd.to_datetime(weather_df['Time'], format='%H:%M')\n",
    "    weather_row = weather_df[weather_df['Time'].dt.hour == hour]\n",
    "    if weather_row.empty:\n",
    "        print(f\"No weather data found for installation {row['id_licznika']} at {hour}:00.\")\n",
    "        continue \n",
    "    print(weather_row)\n",
    "    print(row)\n",
    "    \n",
    "    # Add the weather data to the DataFrame\n",
    "    installations_with_weather_df.loc[installations_with_weather_df.shape[0]] = {\n",
    "        'id_licznika': row['id_licznika'],\n",
    "        'moc': row['moc'],\n",
    "        'data': row['godzina'],\n",
    "        'dlugosc': row['dlugosc'],\n",
    "        'szerokosc': row['szerokosc'],\n",
    "        'dpv': row['dpv'],\n",
    "        'efekt': row['efekt'],\n",
    "        'temperatura': weather_row['Temperature'].values[0],\n",
    "        'zachmurzenie': weather_row['Cloudiness'].values[0],\n",
    "        'wilgotnosc': weather_row['Humidity'].values[0],\n",
    "        'wiatr': weather_row['Wind Speed'].values[0]}\n",
    "\n",
    "print(installations_with_weather_df.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14890ba6e6c1772e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
